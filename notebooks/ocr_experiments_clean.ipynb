{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0zmCfDhkj3t"
      },
      "source": [
        "# Environment Setup (Google Colab)\n",
        "\n",
        "This project was originally developed and experimented in Google Colab.  \n",
        "The following cells handle environment-specific setup and dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Avoid conflicts with PaddleOCR\n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "\n",
        "# PaddleOCR\n",
        "!python -m pip install paddlepaddle-gpu==3.2.0 -i https://www.paddlepaddle.org.cn/packages/stable/cu126/\n",
        "!pip install \"paddleocr>=2.7\"\n",
        "\n",
        "!pip install konlpy"
      ],
      "metadata": {
        "id": "7j61mKeBnM_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRpYSm4qkx86"
      },
      "source": [
        "# Preprocessing\n",
        "This code is saved as src/preprocessing.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39oAZ3_dnL6R"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import os\n",
        "from PIL import Image, ImageSequence\n",
        "\n",
        "class KoreanTextPreprocessorV3:\n",
        "\n",
        "    def __init__(self, debug_mode=True):\n",
        "        self.debug_mode = debug_mode\n",
        "        self.debug_dir = Path(\"/content/debug_output_v7\")\n",
        "        if debug_mode:\n",
        "            self.debug_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "    # --- Debug ---\n",
        "    def _save_debug_image(self, image, name):\n",
        "        if self.debug_mode:\n",
        "            try:\n",
        "                debug_path = self.debug_dir / f\"{name}.png\"\n",
        "                cv2.imwrite(str(debug_path), image)\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not save debug image {name}: {str(e)}\")\n",
        "\n",
        "    # --- Pipeline xử lý ảnh ---\n",
        "    def enhance_local_contrast(self, image):\n",
        "        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "        l, a, b = cv2.split(lab)\n",
        "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "        cl = clahe.apply(l)\n",
        "        enhanced_lab = cv2.merge([cl, a, b])\n",
        "        enhanced = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)\n",
        "        self._save_debug_image(enhanced, \"1_clahe\")\n",
        "        return enhanced\n",
        "\n",
        "    def denoise(self, image, method='gaussian'):\n",
        "        if method == 'bilateral':\n",
        "            denoised = cv2.bilateralFilter(image, d=7, sigmaColor=50, sigmaSpace=50)\n",
        "        else:\n",
        "            denoised = cv2.GaussianBlur(image, (3, 3), 0)\n",
        "        self._save_debug_image(denoised, \"2_denoised\")\n",
        "        return denoised\n",
        "\n",
        "    def sharpen(self, image, kernel_type='light'):\n",
        "        \"\"\"\n",
        "        kernel_type: 'light' (nhẹ), 'strong' (mạnh, mặc định cũ)\n",
        "        \"\"\"\n",
        "        if kernel_type == 'light':\n",
        "            kernel = np.array([[0, -1, 0],\n",
        "                               [-1, 5, -1],\n",
        "                               [0, -1, 0]])\n",
        "        else:\n",
        "            kernel = np.array([[-1, -1, -1],\n",
        "                               [-1, 9, -1],\n",
        "                               [-1, -1, -1]])\n",
        "        sharpened = cv2.filter2D(image, -1, kernel)\n",
        "        self._save_debug_image(sharpened, f\"3_sharpened_{kernel_type}\")\n",
        "        return sharpened\n",
        "\n",
        "    def adaptive_threshold(self, image, method='gaussian'):\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image\n",
        "        self._save_debug_image(gray, \"4_gray\")\n",
        "        th = cv2.ADAPTIVE_THRESH_MEAN_C if method == 'mean' else cv2.ADAPTIVE_THRESH_GAUSSIAN_C\n",
        "        binary = cv2.adaptiveThreshold(gray, 255, th, cv2.THRESH_BINARY, blockSize=25, C=5)\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2,2))\n",
        "        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
        "        self._save_debug_image(binary, \"5_adaptive_threshold\")\n",
        "        return binary\n",
        "\n",
        "    # --- Deskew ---\n",
        "    def getSkewAngle(self, cvImage) -> float:\n",
        "        gray = cv2.cvtColor(cvImage, cv2.COLOR_BGR2GRAY)\n",
        "        blur = cv2.GaussianBlur(gray, (9, 9), 0)\n",
        "        thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))\n",
        "        dilate = cv2.dilate(thresh, kernel, iterations=5)\n",
        "        contours, _ = cv2.findContours(dilate, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        if not contours:\n",
        "            return 0.0\n",
        "        largestContour = max(contours, key=cv2.contourArea)\n",
        "        minAreaRect = cv2.minAreaRect(largestContour)\n",
        "        angle = minAreaRect[-1]\n",
        "        if angle < -45:\n",
        "            angle = 90 + angle\n",
        "        return -1.0 * angle\n",
        "\n",
        "    def rotateImage(self, cvImage, angle: float):\n",
        "        (h, w) = cvImage.shape[:2]\n",
        "        center = (w // 2, h // 2)\n",
        "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "        rotated = cv2.warpAffine(cvImage, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
        "        return rotated\n",
        "\n",
        "    def deskew(self, cvImage):\n",
        "        angle = self.getSkewAngle(cvImage)\n",
        "        if abs(angle) < 0.90:\n",
        "            deskewed = self.rotateImage(cvImage, -1.0 * angle)\n",
        "            self._save_debug_image(deskewed, \"0_deskewed\")\n",
        "            return deskewed\n",
        "        return cvImage\n",
        "\n",
        "    # --- Smart pick frame ---\n",
        "    def choose_best_frame(self, frames, max_frames=10):\n",
        "        best_score = -1\n",
        "        best_frame = frames[0]\n",
        "        for i, f in enumerate(frames[:max_frames]):\n",
        "            gray = cv2.cvtColor(f, cv2.COLOR_BGR2GRAY)\n",
        "            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "            score = cv2.countNonZero(binary)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_frame = f\n",
        "        return best_frame\n",
        "\n",
        "    # --- Xử lý ảnh / GIF / WebP / JPG động ---\n",
        "    def process_image(self, image_path, output_path=None, denoise_method='gaussian',\n",
        "                      threshold_method='gaussian', enable_deskew=True,\n",
        "                      process_all_frames=False, smart_pick=True):\n",
        "        image_path = Path(image_path)\n",
        "        if not image_path.exists():\n",
        "            raise ValueError(f\"File does not exist: {image_path}\")\n",
        "\n",
        "        # luôn dùng Pillow để mở, để detect ảnh động kể cả .jpg\n",
        "        img = Image.open(str(image_path))\n",
        "        is_animated = getattr(img, \"is_animated\", False)\n",
        "\n",
        "        frames = []\n",
        "        if is_animated:\n",
        "            for i, frame in enumerate(ImageSequence.Iterator(img)):\n",
        "                if not process_all_frames and i > 9:  # giới hạn 10 frame để tiết kiệm\n",
        "                    break\n",
        "                frame_cv = cv2.cvtColor(np.array(frame.convert(\"RGB\")), cv2.COLOR_RGB2BGR)\n",
        "                if enable_deskew:\n",
        "                    frame_cv = self.deskew(frame_cv)\n",
        "                frames.append(frame_cv)\n",
        "\n",
        "            if smart_pick:\n",
        "                image_cv = self.choose_best_frame(frames)\n",
        "            else:\n",
        "                image_cv = frames[0]\n",
        "        else:\n",
        "            image_cv = cv2.imread(str(image_path))\n",
        "            if enable_deskew and image_cv is not None:\n",
        "                image_cv = self.deskew(image_cv)\n",
        "\n",
        "        if image_cv is None:\n",
        "            raise ValueError(f\"Could not load image: {image_path}\")\n",
        "\n",
        "        # pipeline preprocess\n",
        "        processed = self.enhance_local_contrast(image_cv)\n",
        "        processed = self.denoise(processed, method=denoise_method)\n",
        "        processed = self.sharpen(processed)\n",
        "        processed = self.adaptive_threshold(processed, method=threshold_method)\n",
        "        # processed = self.sharpen(processed)\n",
        "\n",
        "        # save nếu cần\n",
        "        if output_path:\n",
        "            ext_out = Path(output_path).suffix.lower()\n",
        "            if ext_out not in [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".gif\", \".webp\"]:\n",
        "                ext_out = \".png\"\n",
        "            output_path = str(output_path).rsplit('.', 1)[0] + ext_out\n",
        "            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "            Image.fromarray(processed).save(output_path)\n",
        "\n",
        "        return processed\n",
        "\n",
        "    # --- Xử lý thư mục ---\n",
        "    def process_directory(self, input_dir, output_dir, process_all_frames=False, smart_pick=True):\n",
        "        input_dir = Path(input_dir)\n",
        "        output_dir = Path(output_dir)\n",
        "        output_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "        extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif', '.webp']\n",
        "        all_files = []\n",
        "        for ext in extensions:\n",
        "            all_files.extend(input_dir.glob(f'*{ext}'))\n",
        "\n",
        "        total_files = len(all_files)\n",
        "        processed_files, failed_files = 0, 0\n",
        "\n",
        "        print(f\"\\nFound {total_files} images to process in {input_dir}\")\n",
        "\n",
        "        for i, input_path in enumerate(all_files, 1):\n",
        "            try:\n",
        "                output_path = output_dir / f\"processed_{input_path.name}\"\n",
        "                print(f\"\\nProcessing [{i}/{total_files}]: {input_path.name}\")\n",
        "                self.process_image(input_path, output_path,\n",
        "                                   process_all_frames=process_all_frames,\n",
        "                                   smart_pick=smart_pick)\n",
        "                print(f\"Success - Saved to: {output_path}\")\n",
        "                processed_files += 1\n",
        "            except Exception as e:\n",
        "                failed_files += 1\n",
        "                print(f\"Error processing {input_path.name}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"\\nProcessing completed:\")\n",
        "        print(f\"Total files: {total_files}\")\n",
        "        print(f\"Successfully processed: {processed_files}\")\n",
        "        print(f\"Failed: {failed_files}\")\n",
        "\n",
        "\n",
        "# --- Main chạy thẳng ---\n",
        "def main():\n",
        "    preprocessor = KoreanTextPreprocessorV3(debug_mode=True)\n",
        "\n",
        "    base_dir = Path(\"/content/drive/MyDrive/OFFICIAL_TEST_FOR_PHASE1/TEST_FOR_PHASE1\")\n",
        "    input_dir = base_dir /  \"images_hyecho\"/\"TCA20172_00.jpg\"\n",
        "    output_dir = base_dir / \"OutputImages\" / \"images_hyecho_demo\"\n",
        "\n",
        "    # Nếu muốn xử lý toàn bộ frame GIF, set process_all_frames=True\n",
        "    preprocessor.process_directory(input_dir, output_dir,\n",
        "                                   process_all_frames=False,\n",
        "                                   smart_pick=True)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDEWcTguk5tn"
      },
      "source": [
        "# Model  \n",
        "This code is saved as src/preprocessing.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAHMxc-QlqHd"
      },
      "outputs": [],
      "source": [
        "from paddleocr import PaddleOCR\n",
        "# ===== Config =====\n",
        "INPUT_DIR = \"/content/drive/MyDrive/OFFICIAL_TEST_FOR_PHASE1/TEST_FOR_PHASE1/OutputImages_ver4/images_hyecho_demo\"    #  folder chứa ảnh\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/OFFICIAL_TEST_FOR_PHASE1/TEST_FOR_PHASE1/OutputOCR_ver4/images_hyecho_demo_processed\"  #  folder lưu kết quả\n",
        "\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# ===== Initialize PaddleOCR =====\n",
        "ocr = PaddleOCR(\n",
        "    lang='korean',\n",
        "    use_doc_orientation_classify=False,\n",
        "    use_doc_unwarping=False,\n",
        "    use_textline_orientation=False\n",
        ")\n",
        "\n",
        "# ===== Run OCR on all images in folder =====\n",
        "img_exts = [\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tif\", \".tiff\",\".gif\",\".webp\"]\n",
        "\n",
        "for img_file in Path(INPUT_DIR).glob(\"*\"):\n",
        "    if img_file.suffix.lower() in img_exts:\n",
        "        print(f\"Processing: {img_file.name}\")\n",
        "        result = ocr.predict(str(img_file))\n",
        "\n",
        "        # Tạo folder con cho mỗi ảnh\n",
        "        save_base = Path(OUTPUT_DIR) / img_file.stem\n",
        "        os.makedirs(save_base, exist_ok=True)\n",
        "\n",
        "        # Lưu kết quả\n",
        "        for res in result:\n",
        "            res.print()\n",
        "            try:\n",
        "                # Một số kết quả có font_size = 0 gây lỗi -> bắt và bỏ qua\n",
        "                res.save_to_img(str(save_base))\n",
        "            except ValueError as e:\n",
        "                if \"font size must be greater than 0\" in str(e):\n",
        "                    print(f\"Bỏ qua save_to_img cho {img_file.name} (font size = 0)\")\n",
        "                else:\n",
        "                    raise\n",
        "            res.save_to_json(str(save_base))\n",
        "\n",
        "print(\"Done! Check results in:\", OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post-Processing\n",
        "This code is saved as src/postprocessing.py"
      ],
      "metadata": {
        "id": "SBU5igBdrm70"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuMkEnpcLK0l"
      },
      "outputs": [],
      "source": [
        "\n",
        "from konlpy.tag import Okt\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def segment_korean_text(text: str, tokenizer=None) -> str:\n",
        "    \"\"\"\n",
        "    text: chuỗi OCR tiếng Hàn\n",
        "    tokenizer: instance Okt hoặc Mecab\n",
        "    return: chuỗi đã tách từ bằng khoảng trắng\n",
        "    \"\"\"\n",
        "    if tokenizer is None:\n",
        "        tokenizer = Okt()\n",
        "    words = tokenizer.morphs(text)  # tách từ\n",
        "    return \" \".join(words)\n",
        "\n",
        "\n",
        "def improve_korean_ocr(input_path: str, output_path: str):\n",
        "    input_file = Path(input_path)\n",
        "    output_file = Path(output_path)\n",
        "\n",
        "    if not input_file.exists():\n",
        "        print(\" File đầu vào không tồn tại:\", input_file)\n",
        "        return\n",
        "\n",
        "\n",
        "    lines = input_file.read_text(encoding=\"utf-8\").splitlines()\n",
        "\n",
        "\n",
        "    okt = Okt()\n",
        "\n",
        "    improved_lines = []\n",
        "    for line in lines:\n",
        "        line_clean = \" \".join(line.split())  # chuẩn hóa khoảng trắng\n",
        "        improved_line = segment_korean_text(line_clean, okt)\n",
        "        improved_lines.append(improved_line)\n",
        "\n",
        "\n",
        "    output_file.write_text(\"\\n\".join(improved_lines), encoding=\"utf-8\")\n",
        "    print(f\" File đã được lưu tại: {output_file}\")\n",
        "\n",
        "\n",
        "input_drive_path = \"/content/drive/MyDrive/OFFICIAL_TEST_FOR_PHASE1/TEST_FOR_PHASE1/OutputOCR_ver4/images_hyecho_demo_processed/processed_A000000173589_03_res.txt\"\n",
        "output_drive_path = \"/content/drive/MyDrive/input_ocr_A000000173589_03_segmented.txt\"\n",
        "improve_korean_ocr(input_drive_path, output_drive_path)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}